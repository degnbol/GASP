#!/usr/bin/env julia
using ArgParse
using MultivariateStats
using DelimitedFiles
using Statistics: mean
# using PyCall instead of NPZ since the latter had a problem with large files.
# If PyCall is installed as specified in install.jl then it will be using the 
# python env called GT. Otherwise the pyimport will result in an error.
using PyCall
DB = pyimport("e3fp.fingerprint.db").FingerprintDatabase

parser = ArgParseSettings(
    usage="E3FP_features.jl [-k DIMENSIONS] [-c] [-h] [infiles...] > outfile.tsv",
    description="""Take E3FP chemical fingerprints, fit an MDS and project the 
    chemicals into a smaller dimensional space and write these features to 
    stdout. This script uses classical MDS and allows for adding new points to 
    a previous MDS, which is useful for quickly testing new chemicals without 
    having to rerun all MDS features and retraining a classifier.""")
@add_arg_table parser begin
    "infiles"
    arg_type = String # default is Any
    nargs = '+'
    help = "E3FP fingerprint infiles (.fpz/.npz). Only the first file is used for 
    fitting the MDS. Dimensionality reduction is performed on all files."
    "--dimensions", "-k"
    arg_type = Int
    default = 2
    help = "Number of dimensions to reduce the fingerprint bitvectors to."
    "--conformers", "-c"
    action = :store_true
    help = "Set distance to zero between multiple conformers made for the same id."
end

# if run as script
if abspath(PROGRAM_FILE) == @__FILE__
    args = ARGS
else
    # if interactive, do an example
    ROOT = readchomp(`git root`)
    CHEM = "$ROOT/results/05-chemicalFeatures"
    sArgs = "-ck 12 $CHEM/acceptors-props/E3FP.fpz $CHEM/DON+betanidin-props/E3FP.fpz"
    args = split(sArgs, ' ')
end
args = parse_args(args, parser, as_symbols=true) |> NamedTuple

"""
Load fingerprints from a fpz (npz) file generated by E3FP.
return: names::Vector{String}, indices::Vector{Vector{Int}}
"""
function load_fprints(path)
    fprints = DB.load(path)
    [fp.name for fp in fprints], [fp.indices for fp in fprints]
end

"Strip info about which conformer it is."
strip_conformer(name::AbstractString) = rsplit(name, '_'; limit=2)[1]

"""
Calculate Hamming distance between fingerprints.
https://e3fp.readthedocs.io/en/latest/_modules/e3fp/fingerprint/metrics/fprint_metrics.html#hamming
"""
function hamming(fp1::Vector{Int}, fp2::Vector{Int})
    length(fp1) + length(fp2) - 2 * length(intersect(fp1, fp2))
end
"""
Calculate Euclidean distance between fingerprints.
https://e3fp.readthedocs.io/en/latest/_modules/e3fp/fingerprint/metrics/fprint_metrics.html#distance
"""
distance(fp1::Vector{Int}, fp2::Vector{Int}) = âˆšhamming(fp1, fp2)

fprints = load_fprints.(args.infiles)

nFit = length(fprints[1][1])
# concat entries from all files
names   = vcat((fps[1] for fps in fprints)...)
indices = vcat((fps[2] for fps in fprints)...)

names = strip_conformer.(names)

# distances to the points in the first file
distances = [distance(fp1, fp2) for fp1 in indices[1:nFit], fp2 in indices]
# Artifically set distances between conformers to zero,
# since they ought to be projected to the same point.
if args.conformers
    for (i, name) in enumerate(names)
        distances[name .== names[1:nFit], i] .= 0.
    end
end

# Classical MDS should be deterministic so we can recalculate the MDS used 
# originally and don't have to store it. This assumes the original fingerprints 
# are perfectly unchanged.
mds = fit(MDS, distances[:, 1:nFit]; distances=true, maxoutdim=args.dimensions)
projs = hcat(predict.(Ref(mds), eachcol(distances); distances=true)...)

# get average position across conformers
uNames = unique(names)
features = hcat([mean(projs[:, name .== names]; dims=2) for name in uNames]...)

# write
decimals = length(string(args.dimensions))
colNames = "MDS_" .* lpad.(1:args.dimensions, decimals, '0')
colNames = ["id"; colNames]
println(join(colNames, '\t'))
writedlm(stdout, [uNames features'])

